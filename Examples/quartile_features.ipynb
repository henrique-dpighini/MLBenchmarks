{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses ML benchmarks to test a pipeline that build a new feature based on the terget variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: MLBenchmarks 0.1\n",
      "Uninstalling MLBenchmarks-0.1:\n",
      "  Successfully uninstalled MLBenchmarks-0.1\n",
      "Collecting git+https://github.com/rcpsilva/MLBenchmarks@main\n",
      "  Cloning https://github.com/rcpsilva/MLBenchmarks (to revision main) to c:\\users\\rcpsi\\appdata\\local\\temp\\pip-req-build-scojp0te\n",
      "  Resolved https://github.com/rcpsilva/MLBenchmarks to commit 1097ed04d634608ee37c97bb9b5516c63109714d\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: psutil in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (5.9.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (4.66.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (2.1.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (65.5.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl->MLBenchmarks==0.1) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->MLBenchmarks==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->MLBenchmarks==0.1) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->MLBenchmarks==0.1) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->MLBenchmarks==0.1) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->MLBenchmarks==0.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->MLBenchmarks==0.1) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rcpsi\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->MLBenchmarks==0.1) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->MLBenchmarks==0.1) (1.16.0)\n",
      "Building wheels for collected packages: MLBenchmarks\n",
      "  Building wheel for MLBenchmarks (setup.py): started\n",
      "  Building wheel for MLBenchmarks (setup.py): finished with status 'done'\n",
      "  Created wheel for MLBenchmarks: filename=MLBenchmarks-0.1-py3-none-any.whl size=17234 sha256=6214ea4039f78f702e95dbeeab81a71f26ab2f25bfe54439a60fd19c1a855ae8\n",
      "  Stored in directory: C:\\Users\\rcpsi\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-vy_ja3vw\\wheels\\c3\\f7\\95\\155bc37c57bbc7281b0addda642a4521ee2d82c583940f9692\n",
      "Successfully built MLBenchmarks\n",
      "Installing collected packages: MLBenchmarks\n",
      "Successfully installed MLBenchmarks-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rcpsilva/MLBenchmarks 'C:\\Users\\rcpsi\\AppData\\Local\\Temp\\pip-req-build-scojp0te'\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y MLBenchmarks && pip install git+https://github.com/rcpsilva/MLBenchmarks@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLBenchmarks import classification_datasets_loaders as cdls\n",
    "from MLBenchmarks import regression_datasets_loaders as rdls\n",
    "from MLBenchmarks.benchmarking_methods import load_regression_datasets, run_cross_dataset_benchmark_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom transformer (feature_model) to predict quartiles based on X\n",
    "class QuartileRandomForest(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.quartile_classifier = RandomForestClassifier()  # You can use any classifier here\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Calculate quartiles for y\n",
    "        sorted_y = np.sort(y)\n",
    "        q1 = np.percentile(sorted_y, 25)\n",
    "        q2 = np.percentile(sorted_y, 50)\n",
    "        q3 = np.percentile(sorted_y, 75)\n",
    "        \n",
    "        # Create quartile labels for y\n",
    "        quartile_labels = np.array([self.get_quartile_label(value, q1, q2, q3) for value in y])\n",
    "        \n",
    "        # Fit the quartile classifier\n",
    "        self.quartile_classifier.fit(X, quartile_labels)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Predict quartiles for X\n",
    "        predicted_quartiles = self.quartile_classifier.predict(X).reshape(-1, 1)\n",
    "        return predicted_quartiles\n",
    "    \n",
    "    def get_quartile_label(self, value, q1, q2, q3):\n",
    "        if value <= q1:\n",
    "            return 1\n",
    "        elif value <= q2:\n",
    "            return 2\n",
    "        elif value <= q3:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom transformer (feature_model) to predict quartiles based on X\n",
    "class QuartileDecisionTree(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.quartile_classifier = DecisionTreeClassifier()  # You can use any classifier here\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Calculate quartiles for y\n",
    "        sorted_y = np.sort(y)\n",
    "        q1 = np.percentile(sorted_y, 25)\n",
    "        q2 = np.percentile(sorted_y, 50)\n",
    "        q3 = np.percentile(sorted_y, 75)\n",
    "        \n",
    "        # Create quartile labels for y\n",
    "        quartile_labels = np.array([self.get_quartile_label(value, q1, q2, q3) for value in y])\n",
    "        \n",
    "        # Fit the quartile classifier\n",
    "        self.quartile_classifier.fit(X, quartile_labels)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Predict quartiles for X\n",
    "        predicted_quartiles = self.quartile_classifier.predict(X).reshape(-1, 1)\n",
    "        return predicted_quartiles\n",
    "    \n",
    "    def get_quartile_label(self, value, q1, q2, q3):\n",
    "        if value <= q1:\n",
    "            return 1\n",
    "        elif value <= q2:\n",
    "            return 2\n",
    "        elif value <= q3:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final pipeline with a regression model\n",
    "dt_lr = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileDecisionTree())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', LinearRegression())  # You can use any regression model here\n",
    "])\n",
    "\n",
    "rf_lr = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileRandomForest())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', LinearRegression())  # You can use any regression model here\n",
    "])\n",
    "\n",
    "dt_dt = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileDecisionTree())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', DecisionTreeRegressor())  # You can use any regression model here\n",
    "])\n",
    "\n",
    "rf_dt = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileRandomForest())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', DecisionTreeRegressor())  # You can use any regression model here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted y: [15.  18.  16.  17.  15.  14.  14.  14.  15.  15.  14.  15.  14.  24.\n",
      " 22.  18.  21.  27.  26.  25.  24.  25.  26.  21.  10.  10.  11.   9.\n",
      " 27.  28.  25.  19.  16.  17.  19.  18.  14.  14.  14.  14.  12.  13.\n",
      " 13.  18.  22.  19.  18.  23.  28.  30.  30.  31.  35.  27.  26.  24.\n",
      " 25.  23.  20.  21.  13.  14.  15.  14.  17.  11.  13.  12.  13.  19.\n",
      " 15.  13.  13.  14.  18.  22.  21.  26.  22.  28.  23.  28.  27.  13.\n",
      " 14.  13.  14.  15.  12.  13.  13.  14.  13.  12.  13.  18.  16.  18.\n",
      " 18.  23.  26.  11.  12.  13.  12.  18.  20.  21.  22.  18.  19.  21.\n",
      " 26.  15.  16.  29.  24.  20.  19.  15.  24.  20.  11.  20.  19.  15.\n",
      " 31.  26.  32.  25.  16.  16.  18.  16.  13.  14.  14.  14.  29.  26.\n",
      " 26.  31.  32.  28.  24.  26.  24.  26.  31.  19.  18.  15.  15.  16.\n",
      " 15.  16.  14.  17.  16.  15.  18.  21.  20.  13.  29.  23.  20.  23.\n",
      " 24.  25.  24.  18.  29.  19.  23.  23.  22.  25.  33.  28.  25.  25.\n",
      " 26.  27.  17.5 16.  15.5 14.5 22.  22.  24.  22.5 29.  24.5 29.  33.\n",
      " 20.  18.  18.5 17.5 29.5 32.  28.  26.5 20.  13.  19.  19.  16.5 16.5\n",
      " 13.  13.  13.  31.5 30.  36.  25.5 33.5 17.5 17.  15.5 15.  17.5 20.5\n",
      " 19.  18.5 16.  15.5 15.5 16.  29.  24.5 26.  25.5 30.5 33.5 30.  30.5\n",
      " 22.  21.5 21.5 43.1 36.1 32.8 39.4 36.1 19.9 19.4 20.2 19.2 20.5 20.2\n",
      " 25.1 20.5 19.4 20.6 20.8 18.6 18.1 19.2 17.7 18.1 17.5 30.  27.5 27.2\n",
      " 30.9 21.1 23.2 23.8 23.9 20.3 17.  21.6 16.2 31.5 29.5 21.5 19.8 22.3\n",
      " 20.2 20.6 17.  17.6 16.5 18.2 16.9 15.5 19.2 18.5 31.9 34.1 35.7 27.4\n",
      " 25.4 23.  27.2 23.9 34.2 34.5 31.8 37.3 28.4 28.8 26.8 33.5 41.5 38.1\n",
      " 32.1 37.2 28.  26.4 24.3 19.1 34.3 29.8 31.3 37.  32.2 46.6 27.9 40.8\n",
      " 44.3 43.4 36.4 30.  44.6 33.8 29.8 32.7 23.7 35.  32.4 27.2 26.6 25.8\n",
      " 23.5 30.  39.1 39.  35.1 32.3 37.  37.7 34.1 34.7 34.4 29.9 33.  33.7\n",
      " 32.4 32.9 31.6 28.1 30.7 25.4 24.2 22.4 26.6 20.2 17.6 28.  27.  34.\n",
      " 31.  29.  27.  24.  36.  37.  31.  38.  36.  36.  36.  34.  38.  32.\n",
      " 38.  25.  38.  26.  22.  32.  36.  27.  27.  44.  32.  28.  31. ]\n"
     ]
    }
   ],
   "source": [
    "dataset = rdls.load_auto_mpg()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "pipeline = rf_dt\n",
    "\n",
    "# Fit the pipeline to the data\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predicted y:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the modified pipeline and selected models to a dictionary dictionary\n",
    "models = {\n",
    "    \"dt+lr\": dt_lr,\n",
    "    \"rf+lr\": rf_lr,\n",
    "    \"dt+dt\": dt_dt,\n",
    "    \"rf+dt\": rf_dt,\n",
    "    \"DT\": DecisionTreeRegressor(),\n",
    "    \"LR\": LinearRegression(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['neg_mean_absolute_percentage_error','neg_mean_absolute_error'] # accepts scikit-learn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load_auto_mpg ...\n",
      "Running load_energy_efficiency_y1 ...\n",
      "Running load_energy_efficiency_y2 ...\n",
      "Running load_forest_fires ...\n",
      "Running load_student_mat ...\n",
      "Running load_student_por ...\n",
      "Running load_wine_quality_red ...\n",
      "Running load_wine_quality_white ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00,  8.51it/s]\n",
      "100%|██████████| 8/8 [00:21<00:00,  2.72s/it]\n",
      "100%|██████████| 8/8 [00:01<00:00,  4.69it/s]\n",
      "100%|██████████| 8/8 [00:31<00:00,  3.89s/it]\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.24it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 39.83it/s]\n",
      "100%|██████████| 6/6 [00:56<00:00,  9.49s/it]\n"
     ]
    }
   ],
   "source": [
    "datasets = load_regression_datasets()\n",
    "output_json = 'quartile_features.json'\n",
    "res = run_cross_dataset_benchmark_models(models, datasets, metrics, output_json, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dt+lr', 'rf+lr', 'dt+dt', 'rf+dt', 'DT', 'LR']\n",
      "['load_auto_mpg', 'load_energy_efficiency_y1', 'load_energy_efficiency_y2', 'load_forest_fires', 'load_student_mat', 'load_student_por', 'load_wine_quality_red', 'load_wine_quality_white']\n",
      "['fit_time', 'score_time', 'test_neg_mean_absolute_percentage_error', 'test_neg_mean_absolute_error', 'memory_usage(MB)']\n",
      "load_auto_mpg\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -0.125 \t +- 0.015\n",
      "\t\t                              rf+lr:\t -0.111 \t +- 0.015\n",
      "\t\t                              dt+dt:\t -0.135 \t +- 0.028\n",
      "\t\t                              rf+dt:\t -0.122 \t +- 0.021\n",
      "\t\t                                 DT:\t -0.121 \t +- 0.012\n",
      "\t\t                                 LR:\t -0.142 \t +- 0.036\n",
      "load_energy_efficiency_y1\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -0.127 \t +- 0.032\n",
      "\t\t                              rf+lr:\t -0.125 \t +- 0.039\n",
      "\t\t                              dt+dt:\t -0.052 \t +- 0.057\n",
      "\t\t                              rf+dt:\t -0.055 \t +- 0.064\n",
      "\t\t                                 DT:\t -0.050 \t +- 0.058\n",
      "\t\t                                 LR:\t -0.116 \t +- 0.034\n",
      "load_energy_efficiency_y2\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -0.096 \t +- 0.009\n",
      "\t\t                              rf+lr:\t -0.098 \t +- 0.015\n",
      "\t\t                              dt+dt:\t -0.055 \t +- 0.019\n",
      "\t\t                              rf+dt:\t -0.053 \t +- 0.018\n",
      "\t\t                                 DT:\t -0.051 \t +- 0.019\n",
      "\t\t                                 LR:\t -0.095 \t +- 0.013\n",
      "load_forest_fires\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -45992610959808704.000 \t +- 37695845261731232.000\n",
      "\t\t                              rf+lr:\t -41525775615038976.000 \t +- 42522703935416832.000\n",
      "\t\t                              dt+dt:\t -49720941462695208.000 \t +- 56696971816143968.000\n",
      "\t\t                              rf+dt:\t -58162321358912488.000 \t +- 93128870942994240.000\n",
      "\t\t                                 DT:\t -39888748510792536.000 \t +- 34853711272154112.000\n",
      "\t\t                                 LR:\t -33381528676820416.000 \t +- 21329402837633676.000\n",
      "load_student_mat\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -3496652875566713.000 \t +- 2036745060314714.250\n",
      "\t\t                              rf+lr:\t -3133215697002152.500 \t +- 2249645453945555.500\n",
      "\t\t                              dt+dt:\t -3751099436468084.000 \t +- 2304799317625571.000\n",
      "\t\t                              rf+dt:\t -2576743077938562.000 \t +- 1854421071657637.000\n",
      "\t\t                                 DT:\t -2873182547081937.000 \t +- 1961790134905532.250\n",
      "\t\t                                 LR:\t -3819314646851528.000 \t +- 2387177823650080.000\n",
      "load_student_por\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -1130138802173324.000 \t +- 1736111516654057.000\n",
      "\t\t                              rf+lr:\t -1035126418398277.000 \t +- 1654973471819349.000\n",
      "\t\t                              dt+dt:\t -885627361427693.750 \t +- 1416914355761230.750\n",
      "\t\t                              rf+dt:\t -948468286460770.375 \t +- 1541829186902413.250\n",
      "\t\t                                 DT:\t -1095526793076637.250 \t +- 1968725568258130.000\n",
      "\t\t                                 LR:\t -1078339372316330.375 \t +- 1686515308836776.750\n",
      "load_wine_quality_red\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -0.114 \t +- 0.002\n",
      "\t\t                              rf+lr:\t -0.093 \t +- 0.006\n",
      "\t\t                              dt+dt:\t -0.117 \t +- 0.005\n",
      "\t\t                              rf+dt:\t -0.094 \t +- 0.009\n",
      "\t\t                                 DT:\t -0.117 \t +- 0.006\n",
      "\t\t                                 LR:\t -0.094 \t +- 0.003\n",
      "load_wine_quality_white\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                              dt+lr:\t -0.130 \t +- 0.004\n",
      "\t\t                              rf+lr:\t -0.105 \t +- 0.006\n",
      "\t\t                              dt+dt:\t -0.129 \t +- 0.008\n",
      "\t\t                              rf+dt:\t -0.101 \t +- 0.006\n",
      "\t\t                                 DT:\t -0.130 \t +- 0.008\n",
      "\t\t                                 LR:\t -0.105 \t +- 0.005\n"
     ]
    }
   ],
   "source": [
    "models = list(res.keys())\n",
    "datasets = list(res[models[0]].keys())\n",
    "metrics = list(res[models[0]][datasets[0]].keys())\n",
    "\n",
    "print(models)\n",
    "print(datasets)\n",
    "print(metrics)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f'{dataset}')\n",
    "    for metric in metrics[2:3]: # MAPE\n",
    "        print(f'\\t{metric}')\n",
    "        for model in models:\n",
    "            print(f'\\t\\t{model:>35}:\\t {np.mean(res[model][dataset][metric]):.3f} \\t +- {np.std(res[model][dataset][metric]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dt+lr', 'rf+lr', 'dt+dt', 'rf+dt', 'DT', 'LR']\n",
      "['load_auto_mpg', 'load_energy_efficiency_y1', 'load_energy_efficiency_y2', 'load_forest_fires', 'load_student_mat', 'load_student_por', 'load_wine_quality_red', 'load_wine_quality_white']\n",
      "['fit_time', 'score_time', 'test_neg_mean_absolute_percentage_error', 'test_neg_mean_absolute_error', 'memory_usage(MB)']\n",
      "load_auto_mpg\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -2.889 \t +- 0.811\n",
      "\t\t                              rf+lr:\t -2.645 \t +- 1.029\n",
      "\t\t                              dt+dt:\t -3.179 \t +- 1.431\n",
      "\t\t                              rf+dt:\t -2.877 \t +- 1.129\n",
      "\t\t                                 DT:\t -2.825 \t +- 0.804\n",
      "\t\t                                 LR:\t -2.988 \t +- 0.706\n",
      "load_energy_efficiency_y1\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -2.358 \t +- 0.391\n",
      "\t\t                              rf+lr:\t -2.326 \t +- 0.484\n",
      "\t\t                              dt+dt:\t -0.841 \t +- 0.669\n",
      "\t\t                              rf+dt:\t -0.904 \t +- 0.783\n",
      "\t\t                                 DT:\t -0.820 \t +- 0.679\n",
      "\t\t                                 LR:\t -2.324 \t +- 0.374\n",
      "load_energy_efficiency_y2\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -2.300 \t +- 0.184\n",
      "\t\t                              rf+lr:\t -2.313 \t +- 0.256\n",
      "\t\t                              dt+dt:\t -1.389 \t +- 0.355\n",
      "\t\t                              rf+dt:\t -1.335 \t +- 0.337\n",
      "\t\t                                 DT:\t -1.326 \t +- 0.354\n",
      "\t\t                                 LR:\t -2.360 \t +- 0.215\n",
      "load_forest_fires\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -26.937 \t +- 7.219\n",
      "\t\t                              rf+lr:\t -24.901 \t +- 8.592\n",
      "\t\t                              dt+dt:\t -29.549 \t +- 9.070\n",
      "\t\t                              rf+dt:\t -28.080 \t +- 15.725\n",
      "\t\t                                 DT:\t -24.668 \t +- 9.250\n",
      "\t\t                                 LR:\t -22.095 \t +- 8.207\n",
      "load_student_mat\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -4.162 \t +- 0.446\n",
      "\t\t                              rf+lr:\t -4.062 \t +- 0.373\n",
      "\t\t                              dt+dt:\t -3.929 \t +- 0.449\n",
      "\t\t                              rf+dt:\t -3.729 \t +- 0.337\n",
      "\t\t                                 DT:\t -4.228 \t +- 0.490\n",
      "\t\t                                 LR:\t -3.418 \t +- 0.513\n",
      "load_student_por\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -2.751 \t +- 0.355\n",
      "\t\t                              rf+lr:\t -2.494 \t +- 0.297\n",
      "\t\t                              dt+dt:\t -2.727 \t +- 0.301\n",
      "\t\t                              rf+dt:\t -2.576 \t +- 0.338\n",
      "\t\t                                 DT:\t -2.922 \t +- 0.494\n",
      "\t\t                                 LR:\t -2.055 \t +- 0.431\n",
      "load_wine_quality_red\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -0.632 \t +- 0.023\n",
      "\t\t                              rf+lr:\t -0.523 \t +- 0.038\n",
      "\t\t                              dt+dt:\t -0.643 \t +- 0.029\n",
      "\t\t                              rf+dt:\t -0.526 \t +- 0.048\n",
      "\t\t                                 DT:\t -0.638 \t +- 0.020\n",
      "\t\t                                 LR:\t -0.510 \t +- 0.012\n",
      "load_wine_quality_white\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                              dt+lr:\t -0.751 \t +- 0.027\n",
      "\t\t                              rf+lr:\t -0.612 \t +- 0.039\n",
      "\t\t                              dt+dt:\t -0.740 \t +- 0.048\n",
      "\t\t                              rf+dt:\t -0.587 \t +- 0.047\n",
      "\t\t                                 DT:\t -0.748 \t +- 0.046\n",
      "\t\t                                 LR:\t -0.594 \t +- 0.033\n"
     ]
    }
   ],
   "source": [
    "models = list(res.keys())\n",
    "datasets = list(res[models[0]].keys())\n",
    "metrics = list(res[models[0]][datasets[0]].keys())\n",
    "\n",
    "print(models)\n",
    "print(datasets)\n",
    "print(metrics)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f'{dataset}')\n",
    "    for metric in metrics[3:4]: # mean_absolute_error\n",
    "        print(f'\\t{metric}')\n",
    "        for model in models:\n",
    "            print(f'\\t\\t{model:>35}:\\t {np.mean(res[model][dataset][metric]):.3f} \\t +- {np.std(res[model][dataset][metric]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
