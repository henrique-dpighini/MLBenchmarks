{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses ML benchmarks to test a pipeline that build a new feature based on the terget variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: MLBenchmarks 0.1\n",
      "Uninstalling MLBenchmarks-0.1:\n",
      "  Successfully uninstalled MLBenchmarks-0.1\n",
      "Collecting git+https://github.com/rcpsilva/MLBenchmarks@main\n",
      "  Cloning https://github.com/rcpsilva/MLBenchmarks (to revision main) to c:\\users\\rcpsi\\appdata\\local\\temp\\pip-req-build-u_tsam63\n",
      "  Resolved https://github.com/rcpsilva/MLBenchmarks to commit adf664130617dc5ca758ad515ab7da4e919702a8\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: psutil in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (5.9.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (4.66.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (2.1.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from MLBenchmarks==0.1) (65.5.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl->MLBenchmarks==0.1) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->MLBenchmarks==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->MLBenchmarks==0.1) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->MLBenchmarks==0.1) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->MLBenchmarks==0.1) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->MLBenchmarks==0.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->MLBenchmarks==0.1) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rcpsi\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->MLBenchmarks==0.1) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rcpsi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->MLBenchmarks==0.1) (1.16.0)\n",
      "Building wheels for collected packages: MLBenchmarks\n",
      "  Building wheel for MLBenchmarks (setup.py): started\n",
      "  Building wheel for MLBenchmarks (setup.py): finished with status 'done'\n",
      "  Created wheel for MLBenchmarks: filename=MLBenchmarks-0.1-py3-none-any.whl size=17375 sha256=88fe2df939f1402f82cc3f49da9ce2b1e869e30b0a4138d19cca572dadc89dd9\n",
      "  Stored in directory: C:\\Users\\rcpsi\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-rlwl4lp0\\wheels\\c3\\f7\\95\\155bc37c57bbc7281b0addda642a4521ee2d82c583940f9692\n",
      "Successfully built MLBenchmarks\n",
      "Installing collected packages: MLBenchmarks\n",
      "Successfully installed MLBenchmarks-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rcpsilva/MLBenchmarks 'C:\\Users\\rcpsi\\AppData\\Local\\Temp\\pip-req-build-u_tsam63'\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y MLBenchmarks && pip install git+https://github.com/rcpsilva/MLBenchmarks@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLBenchmarks import classification_datasets_loaders as cdls\n",
    "from MLBenchmarks import regression_datasets_loaders as rdls\n",
    "from MLBenchmarks.benchmarking_methods import load_regression_datasets, run_cross_dataset_benchmark_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuartileFeatureRF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.quartile_classifier = RandomForestClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        q1, q2, q3 = np.percentile(np.sort(y), [25, 50, 75])\n",
    "        quartile_labels = [int(value > q1) + int(value > q2) + int(value > q3) for value in y]\n",
    "        self.quartile_classifier.fit(X, quartile_labels)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.quartile_classifier.predict(X).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuartileFeatureDT(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.quartile_classifier = DecisionTreeClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        q1, q2, q3 = np.percentile(np.sort(y), [25, 50, 75])\n",
    "        quartile_labels = [int(value > q1) + int(value > q2) + int(value > q3) for value in y]\n",
    "        self.quartile_classifier.fit(X, quartile_labels)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.quartile_classifier.predict(X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuartileFeatureGB(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.quartile_classifier = GradientBoostingClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        q1, q2, q3 = np.percentile(np.sort(y), [25, 50, 75])\n",
    "        quartile_labels = [int(value > q1) + int(value > q2) + int(value > q3) for value in y]\n",
    "        self.quartile_classifier.fit(X, quartile_labels)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.quartile_classifier.predict(X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final pipeline with a regression model\n",
    "DT_DT = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileFeatureDT())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', DecisionTreeRegressor(max_depth=3))  # You can use any regression model here\n",
    "])\n",
    "\n",
    "\n",
    "DT_RF = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileFeatureRF())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', DecisionTreeRegressor(max_depth=3))  # You can use any regression model here\n",
    "])\n",
    "\n",
    "DT_GB = Pipeline([\n",
    "    ('feature_union', FeatureUnion([\n",
    "                        ('original_features', StandardScaler()),  # Example: Standardize the original features (X)\n",
    "                        ('quartile_feature', QuartileFeatureGB())  # Use the custom quartile predictor\n",
    "                    ])),\n",
    "    ('regression_model', DecisionTreeRegressor(max_depth=3))  # You can use any regression model here\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the modified pipeline and selected models to a dictionary dictionary\n",
    "models = {\n",
    "    \"DT\": DecisionTreeRegressor(max_depth=3),\n",
    "    \"DT_DT\": DT_DT,\n",
    "    \"DT_RF\": DT_RF,\n",
    "    \"DT_GB\": DT_GB,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['neg_mean_absolute_percentage_error','neg_mean_absolute_error'] # accepts scikit-learn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running load_auto_mpg ...\n",
      "Running load_bike_sharing_day ...\n",
      "Running load_bike_sharing_hour ...\n",
      "Running load_energy_efficiency_y1 ...\n",
      "Running load_energy_efficiency_y2 ...\n",
      "Running load_forest_fires ...\n",
      "Running load_real_state_valuation ...\n",
      "Running load_student_mat ...\n",
      "Running load_student_por ...\n",
      "Running load_wine_quality_red ...\n",
      "Running load_wine_quality_white ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 29.23it/s]\n",
      "100%|██████████| 11/11 [00:01<00:00,  7.17it/s]\n",
      "100%|██████████| 11/11 [00:44<00:00,  4.01s/it]\n",
      "100%|██████████| 11/11 [02:00<00:00, 10.92s/it]\n",
      "100%|██████████| 4/4 [02:46<00:00, 41.52s/it]\n"
     ]
    }
   ],
   "source": [
    "datasets = load_regression_datasets()\n",
    "output_json = 'quartile_features.json'\n",
    "res = run_cross_dataset_benchmark_models(models, datasets, metrics, output_json, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'DT_DT', 'DT_RF', 'DT_GB']\n",
      "['load_auto_mpg', 'load_bike_sharing_day', 'load_bike_sharing_hour', 'load_energy_efficiency_y1', 'load_energy_efficiency_y2', 'load_forest_fires', 'load_real_state_valuation', 'load_student_mat', 'load_student_por', 'load_wine_quality_red', 'load_wine_quality_white']\n",
      "['fit_time', 'score_time', 'test_neg_mean_absolute_percentage_error', 'test_neg_mean_absolute_error', 'memory_usage(MB)']\n",
      "load_auto_mpg\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.140 \t +- 0.021\n",
      "\t\t                              DT_DT:\t -0.130 \t +- 0.011\n",
      "\t\t                              DT_RF:\t -0.116 \t +- 0.015\n",
      "\t\t                              DT_GB:\t -0.113 \t +- 0.015\n",
      "load_bike_sharing_day\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.229 \t +- 0.129\n",
      "\t\t                              DT_DT:\t -0.200 \t +- 0.137\n",
      "\t\t                              DT_RF:\t -0.210 \t +- 0.145\n",
      "\t\t                              DT_GB:\t -0.198 \t +- 0.137\n",
      "load_bike_sharing_hour\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.641 \t +- 0.291\n",
      "\t\t                              DT_DT:\t -0.635 \t +- 0.284\n",
      "\t\t                              DT_RF:\t -0.636 \t +- 0.285\n",
      "\t\t                              DT_GB:\t -0.633 \t +- 0.285\n",
      "load_energy_efficiency_y1\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.137 \t +- 0.062\n",
      "\t\t                              DT_DT:\t -0.103 \t +- 0.068\n",
      "\t\t                              DT_RF:\t -0.114 \t +- 0.079\n",
      "\t\t                              DT_GB:\t -0.103 \t +- 0.066\n",
      "load_energy_efficiency_y2\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.095 \t +- 0.027\n",
      "\t\t                              DT_DT:\t -0.081 \t +- 0.020\n",
      "\t\t                              DT_RF:\t -0.080 \t +- 0.018\n",
      "\t\t                              DT_GB:\t -0.070 \t +- 0.016\n",
      "load_forest_fires\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -33801448825862744.000 \t +- 21740113005037016.000\n",
      "\t\t                              DT_DT:\t -62377512823827328.000 \t +- 69689359614653232.000\n",
      "\t\t                              DT_RF:\t -57437080667669624.000 \t +- 93295606437915552.000\n",
      "\t\t                              DT_GB:\t -62197223186478016.000 \t +- 102177047734383840.000\n",
      "load_real_state_valuation\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.168 \t +- 0.035\n",
      "\t\t                              DT_DT:\t -0.173 \t +- 0.019\n",
      "\t\t                              DT_RF:\t -0.156 \t +- 0.018\n",
      "\t\t                              DT_GB:\t -0.159 \t +- 0.013\n",
      "load_student_mat\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -3421131295910038.000 \t +- 2458217487942832.000\n",
      "\t\t                              DT_DT:\t -3031759330213317.500 \t +- 2030602996005803.500\n",
      "\t\t                              DT_RF:\t -2817533281451627.000 \t +- 2203767816110230.500\n",
      "\t\t                              DT_GB:\t -2997091453851969.500 \t +- 2332844751234552.000\n",
      "load_student_por\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -1079755240470236.000 \t +- 1685074815686021.500\n",
      "\t\t                              DT_DT:\t -1027290729722491.250 \t +- 1708240110614626.000\n",
      "\t\t                              DT_RF:\t -983522067082714.750 \t +- 1621182385123420.250\n",
      "\t\t                              DT_GB:\t -990008854655023.625 \t +- 1642198650232510.750\n",
      "load_wine_quality_red\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.101 \t +- 0.004\n",
      "\t\t                              DT_DT:\t -0.113 \t +- 0.007\n",
      "\t\t                              DT_RF:\t -0.092 \t +- 0.003\n",
      "\t\t                              DT_GB:\t -0.090 \t +- 0.005\n",
      "load_wine_quality_white\n",
      "\ttest_neg_mean_absolute_percentage_error\n",
      "\t\t                                 DT:\t -0.108 \t +- 0.005\n",
      "\t\t                              DT_DT:\t -0.131 \t +- 0.006\n",
      "\t\t                              DT_RF:\t -0.099 \t +- 0.005\n",
      "\t\t                              DT_GB:\t -0.100 \t +- 0.006\n"
     ]
    }
   ],
   "source": [
    "models = list(res.keys())\n",
    "datasets = list(res[models[0]].keys())\n",
    "metrics = list(res[models[0]][datasets[0]].keys())\n",
    "\n",
    "print(models)\n",
    "print(datasets)\n",
    "print(metrics)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f'{dataset}')\n",
    "    for metric in metrics[2:3]: # MAPE\n",
    "        print(f'\\t{metric}')\n",
    "        for model in models:\n",
    "            print(f'\\t\\t{model:>35}:\\t {np.mean(res[model][dataset][metric]):.3f} \\t +- {np.std(res[model][dataset][metric]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'DT_DT', 'DT_RF', 'DT_GB']\n",
      "['load_auto_mpg', 'load_bike_sharing_day', 'load_bike_sharing_hour', 'load_energy_efficiency_y1', 'load_energy_efficiency_y2', 'load_forest_fires', 'load_real_state_valuation', 'load_student_mat', 'load_student_por', 'load_wine_quality_red', 'load_wine_quality_white']\n",
      "['fit_time', 'score_time', 'test_neg_mean_absolute_percentage_error', 'test_neg_mean_absolute_error', 'memory_usage(MB)']\n",
      "load_auto_mpg\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -3.224 \t +- 1.050\n",
      "\t\t                              DT_DT:\t -3.003 \t +- 0.820\n",
      "\t\t                              DT_RF:\t -2.716 \t +- 1.008\n",
      "\t\t                              DT_GB:\t -2.634 \t +- 1.002\n",
      "load_bike_sharing_day\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -602.228 \t +- 98.133\n",
      "\t\t                              DT_DT:\t -470.885 \t +- 95.418\n",
      "\t\t                              DT_RF:\t -521.582 \t +- 130.852\n",
      "\t\t                              DT_GB:\t -463.228 \t +- 101.574\n",
      "load_bike_sharing_hour\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -32.697 \t +- 6.197\n",
      "\t\t                              DT_DT:\t -31.884 \t +- 6.610\n",
      "\t\t                              DT_RF:\t -32.305 \t +- 6.268\n",
      "\t\t                              DT_GB:\t -30.987 \t +- 6.868\n",
      "load_energy_efficiency_y1\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -2.475 \t +- 0.611\n",
      "\t\t                              DT_DT:\t -1.985 \t +- 0.828\n",
      "\t\t                              DT_RF:\t -2.150 \t +- 0.987\n",
      "\t\t                              DT_GB:\t -1.948 \t +- 0.753\n",
      "load_energy_efficiency_y2\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -2.280 \t +- 0.413\n",
      "\t\t                              DT_DT:\t -2.038 \t +- 0.382\n",
      "\t\t                              DT_RF:\t -1.996 \t +- 0.334\n",
      "\t\t                              DT_GB:\t -1.766 \t +- 0.269\n",
      "load_forest_fires\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -20.948 \t +- 10.962\n",
      "\t\t                              DT_DT:\t -29.054 \t +- 10.147\n",
      "\t\t                              DT_RF:\t -26.755 \t +- 16.459\n",
      "\t\t                              DT_GB:\t -27.254 \t +- 18.732\n",
      "load_real_state_valuation\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -5.864 \t +- 0.935\n",
      "\t\t                              DT_DT:\t -6.232 \t +- 0.514\n",
      "\t\t                              DT_RF:\t -5.684 \t +- 0.456\n",
      "\t\t                              DT_GB:\t -5.697 \t +- 0.228\n",
      "load_student_mat\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -3.384 \t +- 0.386\n",
      "\t\t                              DT_DT:\t -3.846 \t +- 0.362\n",
      "\t\t                              DT_RF:\t -3.920 \t +- 0.320\n",
      "\t\t                              DT_GB:\t -3.793 \t +- 0.491\n",
      "load_student_por\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -2.365 \t +- 0.419\n",
      "\t\t                              DT_DT:\t -2.712 \t +- 0.388\n",
      "\t\t                              DT_RF:\t -2.507 \t +- 0.269\n",
      "\t\t                              DT_GB:\t -2.501 \t +- 0.505\n",
      "load_wine_quality_red\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -0.552 \t +- 0.024\n",
      "\t\t                              DT_DT:\t -0.622 \t +- 0.027\n",
      "\t\t                              DT_RF:\t -0.514 \t +- 0.027\n",
      "\t\t                              DT_GB:\t -0.494 \t +- 0.029\n",
      "load_wine_quality_white\n",
      "\ttest_neg_mean_absolute_error\n",
      "\t\t                                 DT:\t -0.611 \t +- 0.027\n",
      "\t\t                              DT_DT:\t -0.754 \t +- 0.037\n",
      "\t\t                              DT_RF:\t -0.572 \t +- 0.036\n",
      "\t\t                              DT_GB:\t -0.568 \t +- 0.043\n"
     ]
    }
   ],
   "source": [
    "models = list(res.keys())\n",
    "datasets = list(res[models[0]].keys())\n",
    "metrics = list(res[models[0]][datasets[0]].keys())\n",
    "\n",
    "print(models)\n",
    "print(datasets)\n",
    "print(metrics)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f'{dataset}')\n",
    "    for metric in metrics[3:4]: # mean_absolute_error\n",
    "        print(f'\\t{metric}')\n",
    "        for model in models:\n",
    "            print(f'\\t\\t{model:>35}:\\t {np.mean(res[model][dataset][metric]):.3f} \\t +- {np.std(res[model][dataset][metric]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
